const createCsvWriter = require("csv-writer").createObjectCsvWriter;

const scraperObject = {
  url: "https://www.bbc.com/bengali/topics/cg7265yyxn1t?page=1",
  async scraper(browser) {
    let page = await browser.newPage();
    let countNumber = 0;
    console.log(`Navigating to ${this.url}...`);
    // Navigate to the selected page
    await page.goto(this.url);
    // Wait for the required DOM to be rendered
    await page.waitForSelector("header");

    let data = [];
    let timeoutUrls = []; // Array to store URLs that timed out

    // Function to scrape data from a page
    const scrapePage = async (link) => {
      let dataObj = {};
      let newPage = await browser.newPage();
      try {
        await newPage.goto(link, { timeout: 60000 });
        await newPage.waitForSelector(".bbc-1151pbn > h1");
        console.log(countNumber++);

        // Scrape all h3 elements
        dataObj["blogTitles"] = await newPage.$eval(
          ".bbc-1151pbn > h1",
          (element) => element.textContent
        );

        // Scrape all p elements
        dataObj["blogContent"] = await newPage.$$eval(
          ".bbc-fa0wmp p",
          (elements) => elements.map((el) => el.textContent.trim())
          // .filter((text) => !text.startsWith("jwARI.fetch("))
        );
      } catch (error) {
        console.error(`Error loading URL: ${link}`);
        timeoutUrls.push(link); // Add the URL to the timeoutUrls array
      } finally {
        await newPage.close();
      }
      return dataObj;
    };

    const loadMoreBlogs = async () => {
      let hasMoreButton = true;
      while (hasMoreButton) {
        const moreButton = await page.$(".e19602dz5 > span:last-child a[href]");

        if (!moreButton) {
          hasMoreButton = false;
        } else {
          const isButtonVisible = await moreButton.evaluate((button) => {
            const computedStyle = window.getComputedStyle(button);
            return computedStyle.visibility !== "hidden";
          });

          if (!isButtonVisible) {
            hasMoreButton = false;
          } else {
            try {
              await moreButton.click();
              await page.waitForTimeout(2000); // Wait for the new content to load (adjust the wait time as needed)
            } catch (error) {
              // Handle the error when the "more" button is not clickable
              hasMoreButton = false;
            }
          }
        }
      }
    };

    // Load more blogs and scrape data
    // await loadMoreBlogs();

    // Get the links to all the required blogs
    let urls = await page.evaluate(() => {
      const links = [];
      const linkElements = document.querySelectorAll(".promo-text h2 a");
      linkElements.forEach((el) => {
        const href = el.href;
        // if (
        //   !href.includes(
        //     "https://www.ittefaq.com.bd/topic/%E0%A6%AC%E0%A6%BF%E0%A6%B6%E0%A7%87%E0%A6%B7-%E0%A6%B8%E0%A6%82%E0%A6%AC%E0%A6%BE%E0%A6%A6"
        //   )
        // ) {
        links.push(href);
        // }
      });
      return links;
    });

    console.log(urls);
    // Scrape data from each blog page
    for (let link of urls) {
      let currentPageData = await scrapePage(link);
      data.push(currentPageData);
    }

    // Define CSV writer and write the data to a CSV file
    const csvWriter = createCsvWriter({
      path: "scraped_data.csv",
      header: [
        { id: "blogTitles", title: "Blog Titles" },
        { id: "blogContent", title: "Blog Content" },
      ],
    });

    csvWriter
      .writeRecords(data)
      .then(() => console.log("CSV file written successfully"))
      .catch((error) => console.error("Error writing CSV file:", error));

    // // Export timeout URLs to a separate CSV file
    // if (timeoutUrls.length > 0) {
    //   const timeoutCsvWriter = createCsvWriter({
    //     path: "timeout_urls.csv",
    //     header: [{ id: "url", title: "URL" }],
    //   });

    //   timeoutCsvWriter
    //     .writeRecords(timeoutUrls.map((url) => ({ url })))
    //     .then(() => console.log("Timeout URLs exported to timeout_urls.csv"))
    //     .catch((error) =>
    //       console.error("Error exporting timeout URLs:", error)
    // );
    // }
  },
};

module.exports = scraperObject;
